{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run for linear regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run for KNN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run for XGB\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost\n",
    "import math\n",
    "#from __future__ import division\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#from sklearn import cross_validation, tree, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def remove_outliers(df):\n",
    "    return df[(np.abs(stats.zscore(df)) < 5).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_records = pd.read_csv('dengue_features_train.csv')\n",
    "testing_records = pd.read_csv('dengue_features_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              year  weekofyear     ndvi_ne     ndvi_nw     ndvi_se  \\\n",
      "count   676.000000  676.000000  673.000000  673.000000  673.000000   \n",
      "mean   2006.500000   26.464497    0.264569    0.246152    0.252087   \n",
      "std       3.777712   14.992450    0.079827    0.078274    0.076041   \n",
      "min    2000.000000    1.000000    0.061729    0.035860    0.029880   \n",
      "25%    2003.000000   13.750000    0.201943    0.186629    0.196557   \n",
      "50%    2006.500000   26.000000    0.263643    0.241429    0.250357   \n",
      "75%    2010.000000   39.000000    0.319814    0.299500    0.302300   \n",
      "max    2013.000000   53.000000    0.508357    0.464800    0.538314   \n",
      "\n",
      "          ndvi_sw  precipitation_amt_mm  reanalysis_air_temp_k  \\\n",
      "count  673.000000            672.000000             672.000000   \n",
      "mean     0.270362             62.778333             297.844165   \n",
      "std      0.086063             34.557077               1.155995   \n",
      "min      0.064183              0.000000             294.554286   \n",
      "25%      0.206843             38.995000             297.092500   \n",
      "50%      0.265614             58.655000             297.815000   \n",
      "75%      0.328057             83.757500             298.568929   \n",
      "max      0.546017            210.830000             301.935714   \n",
      "\n",
      "       reanalysis_avg_temp_k  reanalysis_dew_point_temp_k  ...  \\\n",
      "count             672.000000                   672.000000  ...   \n",
      "mean              299.111214                   295.513157  ...   \n",
      "std                 1.326678                     1.378750  ...   \n",
      "min               294.892857                   290.088571  ...   \n",
      "25%               298.205357                   294.627500  ...   \n",
      "50%               299.071429                   295.875714  ...   \n",
      "75%               300.071429                   296.543214  ...   \n",
      "max               303.328571                   298.450000  ...   \n",
      "\n",
      "       reanalysis_precip_amt_kg_per_m2  reanalysis_relative_humidity_percent  \\\n",
      "count                       672.000000                            672.000000   \n",
      "mean                         61.092024                             88.863576   \n",
      "std                          51.483816                              7.385234   \n",
      "min                           0.000000                             57.787143   \n",
      "25%                          26.125000                             84.686786   \n",
      "50%                          49.340000                             91.210714   \n",
      "75%                          79.375000                             94.595357   \n",
      "max                         362.030000                             98.610000   \n",
      "\n",
      "       reanalysis_sat_precip_amt_mm  reanalysis_specific_humidity_g_per_kg  \\\n",
      "count                    672.000000                             672.000000   \n",
      "mean                      62.778333                              17.123563   \n",
      "std                       34.557077                               1.410123   \n",
      "min                        0.000000                              12.111429   \n",
      "25%                       38.995000                              16.155000   \n",
      "50%                       58.655000                              17.450000   \n",
      "75%                       83.757500                              18.176786   \n",
      "max                      210.830000                              20.461429   \n",
      "\n",
      "       reanalysis_tdtr_k  station_avg_temp_c  station_diur_temp_rng_c  \\\n",
      "count         672.000000          629.000000               629.000000   \n",
      "mean            9.233355           27.533290                10.606971   \n",
      "std             2.381186            0.889584                 1.531324   \n",
      "min             3.714286           21.400000                 5.200000   \n",
      "25%             7.400000           27.000000                 9.533333   \n",
      "50%             9.021429           27.600000                10.633333   \n",
      "75%            11.000000           28.100000                11.666667   \n",
      "max            16.028571           30.800000                15.800000   \n",
      "\n",
      "       station_max_temp_c  station_min_temp_c  station_precip_mm  \n",
      "count          661.000000          661.000000         657.000000  \n",
      "mean            33.994554           21.172466          55.928615  \n",
      "std              1.321145            1.272756          58.689751  \n",
      "min             29.600000           14.200000           0.000000  \n",
      "25%             33.200000           20.600000          15.000000  \n",
      "50%             34.000000           21.300000          38.800000  \n",
      "75%             34.900000           22.000000          77.000000  \n",
      "max             42.200000           24.200000         543.300000  \n",
      "\n",
      "[8 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "training_records_sj = training_records[training_records['city'] == 'sj'].drop('city', 1)\n",
    "training_records_iq = training_records[training_records['city'] == 'iq'].drop('city', 1)\n",
    "testing_records_sj = testing_records[testing_records['city'] == 'sj'].drop('city', 1)\n",
    "testing_records_iq = testing_records[testing_records['city'] == 'iq'].drop('city', 1)\n",
    "records_iq = pd.concat([training_records_iq, testing_records_iq], ignore_index=True)\n",
    "records_sj = pd.concat([training_records_sj, testing_records_sj], ignore_index=True)\n",
    "print (records_iq.describe())\n",
    "#records_iq=remove_outliers(records_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_iq['station_averaged_temp'] = records_iq[ ['station_avg_temp_c', 'station_max_temp_c', 'station_min_temp_c']].interpolate().mean(axis=1)\n",
    "records_sj['station_averaged_temp'] = records_sj[['station_avg_temp_c', 'station_max_temp_c', 'station_min_temp_c']].interpolate().mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_iq.to_csv('./Files/PreProcessed-features-iq.csv', index=False)\n",
    "records_sj.to_csv('./Files/PreProcessed-features-sj.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_targets = pd.read_csv('dengue_labels_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_targets.drop(['year'], axis=1, inplace=True)\n",
    "training_targets['week_start_date'] = training_records['week_start_date']\n",
    "training_targets_sj = training_targets[training_targets['city'] == 'sj'].drop('city', 1)\n",
    "training_targets_iq = training_targets[training_targets['city'] == 'iq'].drop('city', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_targets_iq.to_csv('./Files/PreProcessed-labels-train-iq.csv', index=False)\n",
    "training_targets_sj.to_csv('./Files/PreProcessed-labels-train-sj.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_iq = pd.read_csv(\n",
    "    './Files/PreProcessed-features-iq.csv', \n",
    "    parse_dates=['week_start_date'],\n",
    "    index_col='week_start_date'\n",
    ").interpolate()\n",
    "records_sj = pd.read_csv(\n",
    "    './Files/PreProcessed-features-sj.csv', \n",
    "    parse_dates=['week_start_date'],\n",
    "    index_col='week_start_date'\n",
    ").interpolate()\n",
    "labels_iq = pd.read_csv(\n",
    "    './Files/PreProcessed-labels-train-iq.csv',\n",
    "    parse_dates=['week_start_date'],\n",
    "    index_col='week_start_date'\n",
    ")\n",
    "labels_sj = pd.read_csv(\n",
    "    './Files/PreProcessed-labels-train-sj.csv',\n",
    "    parse_dates=['week_start_date'],\n",
    "    index_col='week_start_date'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(Id, totalRecords,labels,numOfTrain , period ,features):\n",
    "    ##One hot encode weekofyear\n",
    "    totalRecords=remove_outliers(totalRecords)\n",
    "    weeks = pd.get_dummies(totalRecords['weekofyear'], prefix='w')\n",
    "    train_time , test_time = weeks[:numOfTrain].reset_index().drop('week_start_date'\n",
    "                                                                 , axis=1) ,weeks[numOfTrain:].reset_index().drop('week_start_date', axis=1)\n",
    "    train_cases = labels[['total_cases']].reset_index().drop('week_start_date', axis=1)\n",
    "    \n",
    "    ####Seasonality prediction model\n",
    "    seasonal_model = LinearRegression()\n",
    "    seasonal_model.fit(train_time, train_cases)\n",
    "    \n",
    "    seasonal_train = pd.Series(\n",
    "        seasonal_model.predict(train_time).flatten()).rolling(5, min_periods=1, center=True).mean()\n",
    "    \n",
    "    train_trendComponent = train_cases.total_cases - seasonal_train\n",
    "    \n",
    "    trend = totalRecords[features].reset_index().drop('week_start_date', axis=1).rolling(period).mean()\n",
    "    \n",
    "    train_trend = trend[period:numOfTrain]\n",
    "    test_trend = trend[numOfTrain:]\n",
    "    train_remainder = train_trendComponent[period:]\n",
    "    \n",
    "    ####Trend prediction model\n",
    "    trend_model = LinearRegression()\n",
    "    trend_model.fit(train_trend, train_remainder)\n",
    "    train_pred_trend = pd.Series(trend_model.predict(train_trend).flatten())\n",
    "\n",
    "    print('Mean_absolute_error for example '+str(Id) +\" - \"+ str(mean_absolute_error(y_pred=train_pred_trend.values + seasonal_train[period:].values,\n",
    "                    y_true=train_cases['total_cases'][period:].values)))\n",
    "\n",
    "    predicted_seasonal = pd.Series(seasonal_model.predict(test_time).flatten())-1\n",
    "    predicted_trend = pd.Series(trend_model.predict(test_trend).flatten())\n",
    "\n",
    "    pred = (predicted_trend + predicted_seasonal).rolling(5, min_periods=1, center=True).mean().astype(int)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictionsX(Id, totalRecords,labels,numOfTrain , period ,features):\n",
    "    ##One hot encode weekofyear\n",
    "    weeks = pd.get_dummies(totalRecords['weekofyear'], prefix='w')\n",
    "    train_time , test_time = weeks[:numOfTrain].reset_index().drop('week_start_date'\n",
    "                                                                 , axis=1) ,weeks[numOfTrain:].reset_index().drop('week_start_date', axis=1)\n",
    "    train_cases = labels[['total_cases']].reset_index().drop('week_start_date', axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    seasonal_model = LinearRegression()\n",
    "#     seasonal_model = xgboost.XGBRegressor(base_score=0.5, booster='gbtree',\n",
    "#                                         colsample_bylevel=1, colsample_bytree=1,\n",
    "#                                         gamma=0, importance_type='gain',\n",
    "#                                         learning_rate=0.1, max_delta_step=0,\n",
    "#                                         max_depth=3, min_child_weight=1,\n",
    "#                                         missing=None, n_estimators=100, n_jobs=1,\n",
    "#                                         nthread=None, objective='reg:linear',\n",
    "#                                         random_state=0, reg_alpha=0,\n",
    "#                                         subsample=1)\n",
    "    seasonal_model.fit(train_time, train_cases)  #fit the model\n",
    "    seasonal_train = pd.Series(\n",
    "    seasonal_model.predict(train_time).flatten()).rolling(5, min_periods=1, center=True).mean()\n",
    "    train_trendComponent = train_cases.total_cases - seasonal_train\n",
    "    trend = totalRecords[features].reset_index().drop('week_start_date', axis=1).rolling(period).mean()\n",
    "\n",
    "    train_trend = trend[period:numOfTrain]\n",
    "    test_trend = trend[numOfTrain:]\n",
    "    train_remainder = train_trendComponent[period:]\n",
    "        \n",
    "    \n",
    "    #trend_model = neighbors.KNeighborsRegressor(n_neighbors = N)    \n",
    "####Trend prediction model\n",
    "    trend_model = xgboost.XGBRegressor(base_score=0.5, booster='gbtree',\n",
    "                                            colsample_bylevel=1, colsample_bytree=1,\n",
    "                                            gamma=0, importance_type='gain',\n",
    "                                            learning_rate=0.1, max_delta_step=0,\n",
    "                                            max_depth=3, min_child_weight=1,\n",
    "                                            missing=None, n_estimators=100, n_jobs=1,\n",
    "                                            nthread=None, objective='reg:linear',\n",
    "                                            random_state=0, reg_alpha=0,\n",
    "                                            subsample=1)\n",
    "    #trend_model = LinearRegression()\n",
    "    trend_model.fit(train_trend, train_remainder)\n",
    "    train_pred_trend = pd.Series(trend_model.predict(train_trend).flatten())\n",
    "\n",
    "    print('Mean_absolute_error for XGB'+\" - \"+ str(mean_absolute_error(y_pred=train_pred_trend.values + seasonal_train[period:].values,\n",
    "                    y_true=train_cases['total_cases'][period:].values)))\n",
    "    \n",
    "    predicted_seasonal = pd.Series(seasonal_model.predict(test_time).flatten())-1\n",
    "    predicted_trend = pd.Series(trend_model.predict(test_trend).flatten())\n",
    "    \n",
    "    pred = (predicted_trend + predicted_seasonal).rolling(5, min_periods=1, center=True).mean().astype(int)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictionsK(Id, totalRecords,labels,numOfTrain , period ,features):\n",
    "    totalRecords=remove_outliers(totalRecords)\n",
    "    ##One hot encode weekofyear\n",
    "    weeks = pd.get_dummies(totalRecords['weekofyear'], prefix='w')\n",
    "    train_time , test_time = weeks[:numOfTrain].reset_index().drop('week_start_date'\n",
    "                                                                 , axis=1) ,weeks[numOfTrain:].reset_index().drop('week_start_date', axis=1)\n",
    "    train_cases = labels[['total_cases']].reset_index().drop('week_start_date', axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    seasonal_model = neighbors.KNeighborsRegressor(n_neighbors = 20)\n",
    "\n",
    "    seasonal_model.fit(train_time, train_cases)  #fit the model\n",
    "    seasonal_train = pd.Series(\n",
    "    seasonal_model.predict(train_time).flatten()).rolling(5, min_periods=1, center=True).mean()\n",
    "    train_trendComponent = train_cases.total_cases - seasonal_train\n",
    "    trend = totalRecords[features].reset_index().drop('week_start_date', axis=1).rolling(period).mean()\n",
    "\n",
    "    train_trend = trend[period:numOfTrain]\n",
    "    test_trend = trend[numOfTrain:]\n",
    "    train_remainder = train_trendComponent[period:]\n",
    "        \n",
    "    \n",
    "    #trend_model = neighbors.KNeighborsRegressor(n_neighbors = N)    \n",
    "####Trend prediction model\n",
    "#     trend_model = xgboost.XGBRegressor(base_score=0.5, booster='gbtree',\n",
    "#                                             colsample_bylevel=1, colsample_bytree=1,\n",
    "#                                             gamma=0, importance_type='gain',\n",
    "#                                             learning_rate=0.1, max_delta_step=0,\n",
    "#                                             max_depth=3, min_child_weight=1,\n",
    "#                                             missing=None, n_estimators=100, n_jobs=1,\n",
    "#                                             nthread=None, objective='reg:linear',\n",
    "#                                             random_state=0, reg_alpha=0,\n",
    "#                                             subsample=1)\n",
    "    trend_model = LinearRegression()\n",
    "    trend_model.fit(train_trend, train_remainder)\n",
    "    train_pred_trend = pd.Series(trend_model.predict(train_trend).flatten())\n",
    "\n",
    "    print('Mean_absolute_error for K N'+\" \"+\" - \"+ str(mean_absolute_error(y_pred=train_pred_trend.values + seasonal_train[period:].values,\n",
    "                    y_true=train_cases['total_cases'][period:].values)))\n",
    "    \n",
    "    predicted_seasonal = pd.Series(seasonal_model.predict(test_time).flatten())-1\n",
    "    predicted_trend = pd.Series(trend_model.predict(test_trend).flatten())\n",
    "  \n",
    "    pred = (predicted_trend + predicted_seasonal).rolling(5, min_periods=1, center=True).mean().astype(int)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictionsiq(Id, totalRecords,labels,numOfTrain , period ,features):\n",
    "    #totalRecords=remove_outliers(totalRecords)\n",
    "    ##One hot encode weekofyear\n",
    "    weeks = pd.get_dummies(totalRecords['weekofyear'], prefix='w')\n",
    "    train_time , test_time = weeks[:numOfTrain].reset_index().drop('week_start_date'\n",
    "                                                                 , axis=1) ,weeks[numOfTrain:].reset_index().drop('week_start_date', axis=1)\n",
    "    train_cases = labels[['total_cases']].reset_index().drop('week_start_date', axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    seasonal_model =  LinearRegression()\n",
    "\n",
    "    seasonal_model.fit(train_time, train_cases)  #fit the model\n",
    "    seasonal_train = pd.Series(\n",
    "    seasonal_model.predict(train_time).flatten()).rolling(5, min_periods=1, center=True).mean()\n",
    "    train_trendComponent = train_cases.total_cases - seasonal_train\n",
    "    trend = totalRecords[features].reset_index().drop('week_start_date', axis=1).rolling(period).mean()\n",
    "\n",
    "    train_trend = trend[period:numOfTrain]\n",
    "    test_trend = trend[numOfTrain:]\n",
    "    train_remainder = train_trendComponent[period:]\n",
    "        \n",
    "    \n",
    "    \n",
    "    trend_model = LinearRegression()\n",
    "    trend_model.fit(train_trend, train_remainder)\n",
    "    train_pred_trend = pd.Series(trend_model.predict(train_trend).flatten())\n",
    "\n",
    "    print('Mean_absolute_error for K N'+\" \"+\" - \"+ str(mean_absolute_error(y_pred=train_pred_trend.values + seasonal_train[period:].values,\n",
    "                    y_true=train_cases['total_cases'][period:].values)))\n",
    "    \n",
    "    predicted_seasonal = pd.Series(seasonal_model.predict(test_time).flatten())-1\n",
    "    predicted_trend = pd.Series(trend_model.predict(test_trend).flatten())\n",
    "  \n",
    "    pred = (predicted_trend + predicted_seasonal).rolling(5, min_periods=1, center=True).mean().astype(int)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_absolute_error for K N  - 6.210521974132924\n",
      "Mean_absolute_error for K N  - 24.58401674082241\n"
     ]
    }
   ],
   "source": [
    "pred_iq = getPredictionsiq(1,records_iq, labels_iq, 520, 53, [\n",
    "    'reanalysis_precip_amt_kg_per_m2','reanalysis_relative_humidity_percent', 'station_averaged_temp'\n",
    "])\n",
    "pred_sj = getPredictionsK(2,records_sj, labels_sj, 936, 53, [\n",
    "    'reanalysis_precip_amt_kg_per_m2', 'reanalysis_relative_humidity_percent','station_averaged_temp'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_start_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-04-30</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-05-07</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-05-14</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-05-21</th>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-05-28</th>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 weekofyear  total_cases\n",
       "week_start_date                         \n",
       "1990-04-30               18            4\n",
       "1990-05-07               19            5\n",
       "1990-05-14               20            4\n",
       "1990-05-21               21            3\n",
       "1990-05-28               22            6"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_sj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_sj=labels_sj.reset_index('week_start_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdnew=pd.DataFrame()\n",
    "pdnew['test']=pd.concat([pred_sj, pred_iq], ignore_index=True)\n",
    "labels_sj['total_cases']\n",
    "pdnew['predicted']=pred_sj\n",
    "pdnew.plot()\n",
    "print(pdnew.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results 1 Liner regression\n",
    "# Mean_absolute_error for example 1 - 6.210521974132924\n",
    "# Mean_absolute_error for example 2 - 25.249237675999417\n",
    "# DataDriven Score-19.8010\n",
    "\n",
    "# results 2 Kneighbour for Seasonal LR for trend\n",
    "# Mean_absolute_error for example 1 - 6.2150369821564215\n",
    "# Mean_absolute_error for example 2 - 24.980501857728154\n",
    "# DataDriven Score- 19.6010\n",
    "\n",
    "# Mean_absolute_error for K N  - 6.301117593973922\n",
    "# Mean_absolute_error for K N  - 24.58401674082241\n",
    "\n",
    "# Mean_absolute_error for K N20 10 - 6.2150369821564215\n",
    "# Mean_absolute_error for K N20 10 - 24.980501857728154\n",
    "\n",
    "# Mean_absolute_error for K N11 10 - 4.900951917461555\n",
    "# Mean_absolute_error for K N20 10 - 18.849239618724045\n",
    "\n",
    "\n",
    "# results 2 Xgb for Seasonal LR for trend\n",
    "# Mean_absolute_error for XGB - 6.209621037814484\n",
    "# Mean_absolute_error for XGB - 25.109268060571907\n",
    "\n",
    "\n",
    "# results 2 Xgb for Seasonal LR for trend for IQ\n",
    "# results 2 KNN for Seasonal LR for trend for SJ\n",
    "# Mean_absolute_error for XGB - 6.209621037814484\n",
    "# Mean_absolute_error for K N20  - 24.980501857728154\n",
    "# DataDriven Score- 19.6875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.concat([pred_sj, pred_iq], ignore_index=True).round().clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred.to_csv('./Files/Prediction-seasonal-trend-prediction-KNN' + '.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  city  year  weekofyear  total_cases\n",
      "0   sj  2008          18          0.0\n",
      "1   sj  2008          19          1.0\n",
      "2   sj  2008          20          2.0\n",
      "3   sj  2008          21          5.0\n",
      "4   sj  2008          22          8.0\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv(\"submission_format.csv\")\n",
    "\n",
    "submission.total_cases = pred\n",
    "print (submission.head())\n",
    "submission.to_csv(\"KNN+SS_SJ_&LR+LR_IQ.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
